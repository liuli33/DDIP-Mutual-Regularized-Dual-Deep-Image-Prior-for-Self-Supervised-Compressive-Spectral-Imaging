# DDIP: Mutual-Regularized Dual Deep Image Prior for Self-Supervised Compressive Spectral Imaging

Official implementation of **DDIP** for hyperspectral image reconstruction from compressive measurements.

---

## ğŸ“„ Paper Information

**Title:** DDIP: Mutual-Regularized Dual Deep Image Prior for Self-Supervised Compressive Spectral Imaging

**Authors:** Lizhu Liu, Yaonan Wang, Yurong Chen, Hui Zhang

**Institution:** School of Robotics, Hunan University

**Published in:** IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)

**DOI:** [10.1109/TCSVT.2025.3598407](https://doi.org/10.1109/TCSVT.2025.3598407)

ğŸ“– **For technical details, please refer to the paper.**

---

## ğŸ” Overview

DDIP is a self-supervised hyperspectral image reconstruction framework that employs **dual deep image priors with mutual regularization** to overcome the overfitting issue in traditional DIP-based methods.

**Key Features:**
- Self-supervised learning (no training data required)
- Dual-network mutual regularization mechanism
- Adaptive inner-loop optimization strategy
- Compatible with both DD-CASSI and SD-CASSI systems

---

## ğŸ“ Repository Structure

```
DDIP/
â”œâ”€â”€ CASSI_Restoration/              # Main implementation directory
â”‚   â”œâ”€â”€ model/                      # Network architecture (SSFAN)
â”‚   â”œâ”€â”€ Results/                    # Output directory for reconstructed images
â”‚   â”œâ”€â”€ RGB/                        # RGB visualization directory
â”‚   â”œâ”€â”€ func.py                     # Utility functions for data processing
â”‚   â”œâ”€â”€ main_KAIST.py               # Main script for KAIST dataset
â”‚   â”œâ”€â”€ main_real.py                # Main script for real data
â”‚   â”œâ”€â”€ optimization_real.py        # Optimization for real data
â”‚   â”œâ”€â”€ optimziation_HQS_acce.py   # Accelerated HQS optimization
â”‚   â””â”€â”€ test_metric.py              # Evaluation metrics (PSNR, SSIM, SAM)
â”‚
â”œâ”€â”€ Data/                           # Dataset and measurements
â”‚   â”œâ”€â”€ KAIST_Dataset/              # KAIST hyperspectral dataset
â”‚   â””â”€â”€ TSA_real_data/              # Real captured data
â”‚       â”œâ”€â”€ Measurements/           # Compressed measurements
â”‚       â”‚   â”œâ”€â”€ measurement/        # Raw measurement data
â”‚       â”‚   â”œâ”€â”€ scene1.mat ~ scene5.mat
â”‚       â”‚   â””â”€â”€ readcave.py
â”‚       â”œâ”€â”€ TSA_reconstruction/     # Reference reconstructions by DAUHST
â”‚       â”‚   â”œâ”€â”€ rgb/                # RGB visualizations
â”‚       â”‚   â”œâ”€â”€ Recon_scene1.mat ~ Recon_scene5.mat
â”‚       â”‚   â””â”€â”€ readcave.py
â”‚       â”œâ”€â”€ mask.mat                # Coded aperture mask
â”‚       â”œâ”€â”€ mask_3d_shift.mat       # 3D shifted mask
â”‚       â””â”€â”€ mask_3d_shift_uint16.mat
â”‚
â””â”€â”€ README.md
```

**Note:** The `TSA_reconstruction` folder contains reference reconstruction results generated by DAUHST method for comparison.

---

## ğŸš€ Quick Start

### 1. Clone Repository

```bash
git clone https://github.com/LizhuLiu/DDIP.git
cd DDIP
```

### 2. Prepare Dataset

Download the required datasets and place them in the `Data/` directory:
- **KAIST Dataset**: Place in `Data/KAIST_Dataset/`
- **Real Data**: Measurements and masks in `Data/TSA_real_data/`

### 3. Run DDIP

For **KAIST dataset**:
```bash
cd CASSI_Restoration
python main_KAIST.py
```

For **real captured data**:
```bash
cd CASSI_Restoration
python main_real.py
```

Reconstructed results will be saved in the `Results/` directory.

---

## ğŸ“¬ Contact

For questions, please contact:

**Lizhu Liu**  
Hunan University  
Email: [your-email@hnu.edu.cn]

---

## ğŸ“– Citation

If you find this work helpful, please cite:

```bibtex
@article{liu2025ddip,
  title={DDIP: Mutual-Regularized Dual Deep Image Prior for Self-Supervised Compressive Spectral Imaging},
  author={Liu, Lizhu and Wang, Yaonan and Chen, Yurong and Zhang, Hui},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2025},
  doi={10.1109/TCSVT.2025.3598407}
}
```

---

## ğŸ™ Acknowledgements

This work was supported by the National Natural Science Foundation of China (Grants 62027810, 92148204), the National Key R&D Program of China (Grant 2021ZD0114503), and other funding sources listed in the paper.

---

## ğŸ“ License

[To be determined]
